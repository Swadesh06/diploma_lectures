<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer Architecture and Types</title>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Roboto+Slab:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body, html {
            font-family: 'Open Sans', sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 0;
            padding: 0;
            scroll-behavior: smooth;
        }
        .container {
            display: flex;
            max-width: 1200px;
            margin: 0 auto;
            background-color: #f5f5f5;
        }
        .sidebar {
            width: 250px;
            height: 100vh;
            position: sticky;
            top: 0;
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            overflow-y: auto;
        }
        .content {
            flex-grow: 1;
            padding: 40px;
            max-width: 800px;
        }
        h1, h2, h3, h4 {
            font-family: 'Roboto Slab', serif;
            color: #2c3e50;
        }
        h1 { font-size: 2.5em; margin-bottom: 0.5em; }
        h2 { font-size: 2em; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 40px; }
        h3 { font-size: 1.5em; margin-top: 30px; }
        ul { padding-left: 20px; }
        .section {
            background-color: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .sidebar h2 {
            color: #ecf0f1;
            border-bottom: 1px solid #ecf0f1;
            padding-bottom: 10px;
            margin-top: 0;
        }
        .sidebar ul {
            list-style-type: none;
            padding: 0;
        }
        .sidebar li {
            margin-bottom: 10px;
        }
        .sidebar a {
            color: #ecf0f1;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        .sidebar a:hover {
            color: #3498db;
        }
        .image-container {
            max-width: 100%;
            margin: 20px 0;
            text-align: center;
            overflow: hidden;
        }
        .image-container img {
            max-width: 100%;
            max-height: 400px; /* Adjust this value as needed */
            width: auto;
            height: auto;
            object-fit: contain;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        @media (max-width: 768px) {
            .container {
                flex-direction: column;
            }
            .sidebar {
                width: 100%;
                height: auto;
                position: static;
            }
            .content {
                padding: 20px;
            }
            .image-container img {
                max-height: 300px; /* Smaller max-height for mobile devices */
            }
        }
        .table-container {
            overflow-x: auto;
            margin-bottom: 20px;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 20px;
            font-size: 14px;
        }

        th, td {
            border: 1px solid #ddd;
            padding: 10px;
            text-align: left;
            vertical-align: top;
        }

        th {
            background-color: #f2f2f2;
            font-weight: bold;
        }

        tr:nth-child(even) {
            background-color: #f9f9f9;
        }

        @media screen and (max-width: 768px) {
            table {
                font-size: 12px;
            }
            
            th, td {
                padding: 6px;
            }
        }

        @media screen and (max-width: 480px) {
            table {
                font-size: 10px;
            }
            
            th, td {
                padding: 4px;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <aside class="sidebar">
            <h2>Contents</h2>
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#encoder-only">Encoder-Only Architecture</a></li>
                <li><a href="#decoder-only">Decoder-Only Architecture</a></li>
                <li><a href="#encoder-decoder">Encoder-Decoder Architecture</a></li>
                <li><a href="#applications">Applications</a></li>
                <li><a href="#conclusion">Conclusion</a></li>
                <li><a href="#qa">My contact for your queries!</a></li>
            </ul>
        </aside>
        <main class="content">
            <section class="section">
                <h1>Transformer Architecture and Types</h1>
                <h3>Focusing on Encoder-Only, Decoder-Only, and Encoder-Decoder Architectures</h3>
                <p>By Swadesh Swain</p>
                <p>Date: June 26, 2024</p>
            </section>

            <section id="introduction" class="section">
                <h2>Introduction</h2>
                <h3>Overview of Transformer Architectures:</h3>
                <ul>
                    <li>Encoder-Only: Models using only the encoder stack.</li>
                    <li>Decoder-Only: Models using only the decoder stack.</li>
                    <li>Encoder-Decoder: Models using both encoder and decoder stacks.</li>
                </ul>
            </section>

            <section id="encoder-only" class="section">
                <h2>Encoder-Only Architecture</h2>
                <h3>Examples: BERT, RoBERTa, ALBERT</h3>
                <h3>Structure:</h3>
                <ul>
                    <li>Consists of multiple layers of the encoder.</li>
                    <li>Each layer includes self-attention and feed-forward networks.</li>
                </ul>
                <h3>Attention Mechanisms:</h3>
                <h4>Self-Attention:</h4>
                <ul>
                    <li>Purpose: Allows the model to weigh the importance of different words in a sequence relative to each other.</li>
                    <li>How it Works:
                        <ul>
                            <li>Each word (token) in the input sequence generates three vectors: Query (Q), Key (K), and Value (V).</li>
                            <li>The attention score is computed using the dot product of the Query with all Keys, followed by a softmax operation to obtain attention weights.</li>
                            <li>The final output is a weighted sum of the Values based on these attention weights.</li>
                        </ul>
                    </li>
                    <li>Use Cases: Used in both encoder and decoder stacks in transformer models.</li>
                </ul>
                <h3>Positional Encoding: Adds positional information to the input embeddings.</h3>
                <h3>Strengths and Use Cases:</h3>
                <ul>
                    <li>Text Classification: Understanding and categorizing input text.</li>
                    <li>Named Entity Recognition (NER): Identifying and classifying entities in text.</li>
                    <li>Question Answering (QA): Extracting answers from text based on a query.</li>
                    <li>Masked Language Modeling (MLM): Predicting masked tokens to capture bidirectional context.</li>
                </ul>
            </section>

            <section id="decoder-only" class="section">
                <h2>Decoder-Only Architecture</h2>
                <div class="image-container">
                    <img src="DecoderOnly.png" alt="Decoder-Only Transformer Architecture">
                </div>
                <h3>Examples: GPT, GPT-2, GPT-3</h3>
                <h3>Structure:</h3>
                <ul>
                    <li>Consists of multiple layers of the decoder.</li>
                    <li>Each layer includes masked self-attention and feed-forward networks.</li>
                </ul>
                <h3>Attention Mechanisms:</h3>
                <h4>Masked Self-Attention:</h4>
            
                <ul>
                    <li>Purpose: Prevents the model from accessing future tokens in the sequence during training, ensuring the autoregressive property.</li>
                    <li>How it Works:
                        <ul>
                            <li>Similar to self-attention, but the attention score calculation includes a mask that sets the attention weights of future tokens to negative infinity, ensuring they don't contribute to the output.</li>
                        </ul>
                    </li>
                    <li>Use Cases: Used in the decoder stack for tasks requiring sequential generation (e.g., text generation).</li>
                </ul>
                <h3>Strengths and Use Cases:</h3>
                <ul>
                    <li>Text Generation: Creating coherent text based on a prompt.</li>
                    <li>Language Modeling: Predicting the next word in a sequence.</li>
                    <li>Autoregressive Tasks: Generating sequences one token at a time.</li>
                </ul>
            </section>

            <section id="encoder-decoder" class="section">
                <h2>Encoder-Decoder Architecture</h2>
                <div class="image-container">
                    <img src="e_d.png" alt="Masked Self-Attention Mechanism">
                </div>
                <h3>Examples: Original Transformer, T5, BART</h3>
                <h3>Structure:</h3>
                <ul>
                    <li>Includes both an encoder and a decoder stack.</li>
                    <li>The encoder processes the input sequence, and the decoder generates the output sequence.</li>
                </ul>
                <h3>Attention Mechanisms:</h3>
                <h4>Self-Attention (Encoder)</h4>
                <h4>Masked Self-Attention (Decoder)</h4>
                <h4>Cross-Attention (Encoder-Decoder Attention):</h4>
                <div class="image-container">
                    <img src="CA.png" alt="Masked Self-Attention Mechanism">
                </div>
                <ul>
                    <li>Purpose: Allows the decoder to focus on relevant parts of the encoded input sequence when generating each token of the output.</li>
                    <li>How it Works:
                        <ul>
                            <li>The decoder generates Query vectors, and the encoder provides Key and Value vectors.</li>
                            <li>The attention mechanism works similarly to self-attention but between the decoder's queries and the encoder's keys and values.</li>
                        </ul>
                    </li>
                    <li>Use Cases: Essential for tasks requiring understanding of the input sequence to generate related output (e.g., translation, summarization).</li>
                </ul>
                <h3>Strengths and Use Cases:</h3>
                <ul>
                    <li>Machine Translation: Translating text from one language to another.</li>
                    <li>Text Summarization: Condensing long texts into summaries.</li>
                    <li>Text Generation with Context: Generating responses or content based on the input context.</li>
                </ul>
            </section>

            <section id="applications" class="section">
                <h2>Applications of Each Architecture</h2>
                <h3>Encoder-Only:</h3>
                <ul>
                    <li>Sentiment Analysis: Determining the sentiment of text.</li>
                    <li>Named Entity Recognition (NER): Identifying entities like names, dates, and locations.</li>
                    <li>Question Answering (QA): Answering questions based on a given text.</li>
                </ul>
                <h3>Decoder-Only:</h3>
                <ul>
                    <li>Story Writing: Generating creative stories.</li>
                    <li>Dialogue Generation: Creating conversational agents.</li>
                </ul>
                <h3>Encoder-Decoder:</h3>
                <ul>
                    <li>Translation: Converting text between languages.</li>
                    <li>Summarization: Summarizing articles or documents.</li>
                    <li>Conversational Agents: Generating context-aware responses in dialogue systems.</li>
                </ul>
            </section>

            <section id="conclusion" class="section">
                <h2>Conclusion</h2>
                <h3>Comparison: Decoder-only vs Normal Transformers vs Encoder-Only</h3>
                <div class="table-container">
                    <table>
                        <thead>
                            <tr>
                                <th>Decoder-only Transformers</th>
                                <th>Normal Transformers</th>
                                <th>Encoder-only Transformers</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>A Decoder-Only Transformer has a single unit for both encoding the input and generating the output.</td>
                                <td>A normal Transformer uses one unit to encode the input, called the Encoder, and a separate unit to generate the output, called the Decoder.</td>
                                <td>An Encoder-Only Transformer has a single unit for processing and encoding the input, without a separate generation component.</td>
                            </tr>
                            <tr>
                                <td>A Decoder-Only Transformer uses a single type of attention, Masked Self-Attention</td>
                                <td>A normal Transformer uses two types of Attention during inference: Self-Attention and Encoder-Decoder Attention.</td>
                                <td>An Encoder-Only Transformer uses only Self-Attention, allowing each token to attend to all other tokens in the input.</td>
                            </tr>
                            <tr>
                                <td>A Decoder-Only Transformer uses Masked Self-Attention all the time on everything, the input and the output</td>
                                <td>During Training, a normal Transformer uses Masked Self-Attention, but only on the output.</td>
                                <td>An Encoder-Only Transformer uses unmasked Self-Attention throughout, as it doesn't generate sequential outputs.</td>
                            </tr>
                            <tr>
                                <td>Unidirectional attention (can only look at previous tokens)</td>
                                <td>Bidirectional attention in encoder (can look at entire input)</td>
                                <td>Bidirectional attention (can look at entire input in all layers)</td>
                            </tr>
                            <tr>
                                <td>Suitable for text generation tasks</td>
                                <td>Suitable for various tasks including translation and summarization</td>
                                <td>Suitable for tasks that require understanding of input, such as classification and feature extraction</td>
                            </tr>
                            <tr>
                                <td>Generally faster inference due to simpler architecture</td>
                                <td>More versatile but potentially slower due to encoder-decoder structure</td>
                                <td>Efficient for tasks that don't require text generation, as it processes input in parallel</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <h3>Recap:</h3>
                <ul>
                    <li>Encoder-Only: Best for understanding and classifying text.</li>
                    <li>Decoder-Only: Best for generating text.</li>
                    <li>Encoder-Decoder: Best for tasks requiring both understanding and generating text.</li>
                </ul>
                <h3>Future Directions:</h3>
                <ul>
                    <li>Efficiency Improvements: Research on making transformer models more efficient.</li>
                    <li>Interpretability: Efforts to make model decisions more interpretable.</li>
                    <li>Domain Adaptation: Enhancing models for specific domains or tasks.</li>
                </ul>
            </section>

            <section id="qa" class="section">
                <h2>Thank You</h2>
                <p>Thank you for your attention!</p>
                <p>For further questions or discussions: swadeshswain226@gmail.com</p>
            </section>
        </main>
    </div>
</body>
</html>
