<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Transformer Architecture and Types</title>
    <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&family=Roboto+Slab:wght@400;700&display=swap" rel="stylesheet">
    <style>
        body, html {
            font-family: 'Open Sans', sans-serif;
            line-height: 1.6;
            color: #333;
            margin: 0;
            padding: 0;
            scroll-behavior: smooth;
        }
        .container {
            display: flex;
            max-width: 1200px;
            margin: 0 auto;
            background-color: #f5f5f5;
        }
        .sidebar {
            width: 250px;
            height: 100vh;
            position: sticky;
            top: 0;
            background-color: #2c3e50;
            color: #ecf0f1;
            padding: 20px;
            overflow-y: auto;
        }
        .content {
            flex-grow: 1;
            padding: 40px;
            max-width: 800px;
        }
        h1, h2, h3, h4 {
            font-family: 'Roboto Slab', serif;
            color: #2c3e50;
        }
        h1 { font-size: 2.5em; margin-bottom: 0.5em; }
        h2 { font-size: 2em; border-bottom: 2px solid #3498db; padding-bottom: 10px; margin-top: 40px; }
        h3 { font-size: 1.5em; margin-top: 30px; }
        ul { padding-left: 20px; }
        .section {
            background-color: white;
            padding: 30px;
            margin-bottom: 30px;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .sidebar h2 {
            color: #ecf0f1;
            border-bottom: 1px solid #ecf0f1;
            padding-bottom: 10px;
            margin-top: 0;
        }
        .sidebar ul {
            list-style-type: none;
            padding: 0;
        }
        .sidebar li {
            margin-bottom: 10px;
        }
        .sidebar a {
            color: #ecf0f1;
            text-decoration: none;
            transition: color 0.3s ease;
        }
        .sidebar a:hover {
            color: #3498db;
        }
        .image-container {
            max-width: 100%;
            margin: 20px 0;
            text-align: center;
        }
        .image-container img {
            max-width: 100%;
            height: auto;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
    </style>
</head>
<body>
    <div class="container">
        <aside class="sidebar">
            <h2>Contents</h2>
            <ul>
                <li><a href="#introduction">Introduction</a></li>
                <li><a href="#encoder-only">Encoder-Only Architecture</a></li>
                <li><a href="#decoder-only">Decoder-Only Architecture</a></li>
                <li><a href="#encoder-decoder">Encoder-Decoder Architecture</a></li>
                <li><a href="#applications">Applications</a></li>
                <li><a href="#conclusion">Conclusion</a></li>
                <li><a href="#qa">Q&A Session</a></li>
            </ul>
        </aside>
        <main class="content">
            <section class="section">
                <h1>Transformer Architecture and Types</h1>
                <h3>Focusing on Encoder-Only, Decoder-Only, and Encoder-Decoder Architectures</h3>
                <p>By Swadesh Swain</p>
                <p>Date: June 25, 2024</p>
            </section>

            <section id="introduction" class="section">
                <h2>Introduction</h2>
                <h3>Overview of Transformer Architectures:</h3>
                <ul>
                    <li>Encoder-Only: Models using only the encoder stack.</li>
                    <li>Decoder-Only: Models using only the decoder stack.</li>
                    <li>Encoder-Decoder: Models using both encoder and decoder stacks.</li>
                </ul>
            </section>

            <section id="encoder-only" class="section">
                <h2>Encoder-Only Architecture</h2>
                <h3>Examples: BERT, RoBERTa, ALBERT</h3>
                <h3>Structure:</h3>
                <ul>
                    <li>Consists of multiple layers of the encoder.</li>
                    <li>Each layer includes self-attention and feed-forward networks.</li>
                </ul>
                <h3>Attention Mechanisms:</h3>
                <h4>Self-Attention:</h4>
                <ul>
                    <li>Purpose: Allows the model to weigh the importance of different words in a sequence relative to each other.</li>
                    <li>How it Works:
                        <ul>
                            <li>Each word (token) in the input sequence generates three vectors: Query (Q), Key (K), and Value (V).</li>
                            <li>The attention score is computed using the dot product of the Query with all Keys, followed by a softmax operation to obtain attention weights.</li>
                            <li>The final output is a weighted sum of the Values based on these attention weights.</li>
                        </ul>
                    </li>
                    <li>Use Cases: Used in both encoder and decoder stacks in transformer models.</li>
                </ul>
                <h3>Positional Encoding: Adds positional information to the input embeddings.</h3>
                <h3>Strengths and Use Cases:</h3>
                <ul>
                    <li>Text Classification: Understanding and categorizing input text.</li>
                    <li>Named Entity Recognition (NER): Identifying and classifying entities in text.</li>
                    <li>Question Answering (QA): Extracting answers from text based on a query.</li>
                    <li>Masked Language Modeling (MLM): Predicting masked tokens to capture bidirectional context.</li>
                </ul>
            </section>

            <section id="decoder-only" class="section">
                <h2>Decoder-Only Architecture</h2>
                <h3>Examples: GPT, GPT-2, GPT-3</h3>
                <h3>Structure:</h3>
                <ul>
                    <li>Consists of multiple layers of the decoder.</li>
                    <li>Each layer includes masked self-attention and feed-forward networks.</li>
                </ul>
                <h3>Attention Mechanisms:</h3>
                <h4>Masked Self-Attention:</h4>
                <ul>
                    <li>Purpose: Prevents the model from accessing future tokens in the sequence during training, ensuring the autoregressive property.</li>
                    <li>How it Works:
                        <ul>
                            <li>Similar to self-attention, but the attention score calculation includes a mask that sets the attention weights of future tokens to negative infinity, ensuring they don't contribute to the output.</li>
                        </ul>
                    </li>
                    <li>Use Cases: Used in the decoder stack for tasks requiring sequential generation (e.g., text generation).</li>
                </ul>
                <h3>Strengths and Use Cases:</h3>
                <ul>
                    <li>Text Generation: Creating coherent text based on a prompt.</li>
                    <li>Language Modeling: Predicting the next word in a sequence.</li>
                    <li>Autoregressive Tasks: Generating sequences one token at a time.</li>
                </ul>
            </section>

            <section id="encoder-decoder" class="section">
                <h2>Encoder-Decoder Architecture</h2>
                <h3>Examples: Original Transformer, T5, BART</h3>
                <h3>Structure:</h3>
                <ul>
                    <li>Includes both an encoder and a decoder stack.</li>
                    <li>The encoder processes the input sequence, and the decoder generates the output sequence.</li>
                </ul>
                <h3>Attention Mechanisms:</h3>
                <h4>Self-Attention (Encoder)</h4>
                <h4>Masked Self-Attention (Decoder)</h4>
                <h4>Cross-Attention (Encoder-Decoder Attention):</h4>
                <ul>
                    <li>Purpose: Allows the decoder to focus on relevant parts of the encoded input sequence when generating each token of the output.</li>
                    <li>How it Works:
                        <ul>
                            <li>The decoder generates Query vectors, and the encoder provides Key and Value vectors.</li>
                            <li>The attention mechanism works similarly to self-attention but between the decoder's queries and the encoder's keys and values.</li>
                        </ul>
                    </li>
                    <li>Use Cases: Essential for tasks requiring understanding of the input sequence to generate related output (e.g., translation, summarization).</li>
                </ul>
                <h3>Strengths and Use Cases:</h3>
                <ul>
                    <li>Machine Translation: Translating text from one language to another.</li>
                    <li>Text Summarization: Condensing long texts into summaries.</li>
                    <li>Text Generation with Context: Generating responses or content based on the input context.</li>
                </ul>
            </section>

            <section id="applications" class="section">
                <h2>Applications of Each Architecture</h2>
                <h3>Encoder-Only:</h3>
                <ul>
                    <li>Sentiment Analysis: Determining the sentiment of text.</li>
                    <li>Named Entity Recognition (NER): Identifying entities like names, dates, and locations.</li>
                    <li>Question Answering (QA): Answering questions based on a given text.</li>
                </ul>
                <h3>Decoder-Only:</h3>
                <ul>
                    <li>Story Writing: Generating creative stories.</li>
                    <li>Dialogue Generation: Creating conversational agents.</li>
                </ul>
                <h3>Encoder-Decoder:</h3>
                <ul>
                    <li>Translation: Converting text between languages.</li>
                    <li>Summarization: Summarizing articles or documents.</li>
                    <li>Conversational Agents: Generating context-aware responses in dialogue systems.</li>
                </ul>
            </section>

            <section id="conclusion" class="section">
                <h2>Conclusion</h2>
                <h3>Recap:</h3>
                <ul>
                    <li>Encoder-Only: Best for understanding and classifying text.</li>
                    <li>Decoder-Only: Best for generating text.</li>
                    <li>Encoder-Decoder: Best for tasks requiring both understanding and generating text.</li>
                </ul>
                <h3>Future Directions:</h3>
                <ul>
                    <li>Efficiency Improvements: Research on making transformer models more efficient.</li>
                    <li>Interpretability: Efforts to make model decisions more interpretable.</li>
                    <li>Domain Adaptation: Enhancing models for specific domains or tasks.</li>
                </ul>
            </section>

            <section id="qa" class="section">
                <h2>Q&A Session</h2>
                <p>For questions and further discussions, please contact: swadesh_s@ece.iitr.ac.in</p>
            </section>
        </main>
    </div>
</body>
</html>